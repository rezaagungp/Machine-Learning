{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "jumlah dan kualitas data adalah kunci yang mentukan seberapa baik sebuah algoritma machine learing dapat belajar. Oleh karena itu sangat penting untuk mengextract dan melakukan prepreocessing data sebelum data diproses oleh algoritma pembelajaran pada notebook ini akan dibahas mengenai beberapa topik mengenai preprocessing data diantaranya\n",
    "* Menghilangkan dan memasukan missing value dari dataset\n",
    "* Mengubah data keategorikal agar bisa diproses oleh algoritma machine learning\n",
    "* Menentukan feature yang paling relevan untuk pembangunana model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghilangkan dan memasukan missing value dari dataset\n",
    "cara paling mudah untuk mengatasi data yang hilang adalah menghilangkan data tersebut, misal kita memiliki data yang memiliki beberapa feature missing, hilangkan saja feature tersebut dari dataset. untuk dataset yang sedikit kita bisa langsung saja meilihat feautre yang memiliki missing value namun untuk dataset yang berukuran besar kita harus mengecek satu persatu feature yang mengalami missing value dan menjumlahkannya. Panda dataframe menyediakan method ```isnull``` yang akan mereturn dataframe dengan nilai ```boolean``` dengan menggunakan method ```sum``` kita bisa mengetahui statistik missing values per feature. berikut ini adalah contohnya "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "10.0,11.0,12.0,'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B\n",
       "0   1.0   2.0\n",
       "1   5.0   6.0\n",
       "2  10.0  11.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namun seringnnya, menghilangkan data sample atau menghilangkan feature dari dataset bukanlah suatu cara yang layak, karena bisa menyebabkan kehilangan banyak informasi dari data atau feature yang dihilangkan. Untuk mengatasi masalah ini kita bisa mengunakan teknik interpolation untuk mengestimasi nilai dari data yang mengalami missing value. Teknik interpolation yang paling banyak digunakan adalah ***mean imputation***. Cara ini bisa dibilang cukup mudah karena kita mengganti feature yang mengalami missing value dengan nilai rata-rata feature tersebut. Berikut ini adalah implementasi mean imputation dengan menggunakan scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  2. ,  3. ,  4. ],\n",
       "       [ 5. ,  6. ,  7.5,  8. ],\n",
       "       [10. , 11. , 12. ,  6. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "impr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "impr = impr.fit(df)\n",
    "imputed_data = impr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengatasi data categorical\n",
    "pada umumnya data dibagi menjadi dua jenis yaitu ***nominal*** dan ***ordinal*** dimana nominal adalah data yang sifatnya hanya membedakan jenisnya saja dan biasanya tidak bisa diurutkan misalnya warna baju, sednagkan ordinal adalah data yang membedakan jenisnya berdasarkan urutannya shingga biasanya data tipe ordinal terurut misalnya ukuran baju. Sebelum memeahami prepreocessing terhadap data categorical baikya kita membuat dataset untuk data categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warna</th>\n",
       "      <th>ukuran</th>\n",
       "      <th>harga</th>\n",
       "      <th>labelkelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hijau</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>label1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merah</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>label2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biru</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>label1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warna ukuran  harga labelkelas\n",
       "0  hijau      M   10.1     label1\n",
       "1  merah      L   13.5     label2\n",
       "2   biru     XL   15.3     label1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "    ['hijau', 'M', 10.1, 'label1'],\n",
    "    ['merah', 'L', 13.5, 'label2'],\n",
    "    ['biru', 'XL', 15.3, 'label1']\n",
    "])\n",
    "df.columns = ['warna', 'ukuran', 'harga', 'labelkelas']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping ordinal feature\n",
    "untuk memastikan bahwa algoritma learning mengintepretasikan ordinal feature secara tepat. perlu dilakukan konversi data string ke integer. pada scikit-learn tidakmenyediakn method ataupun fungsi yang secara otomatis mengurutkan feature dari ukuran baju sehingga perlu dilakukan mapping secara manual contohnya $XL = L + 1 = M + 2$, berikut ini adalah potongan kode untuk melakukan mapping ukuran baju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warna</th>\n",
       "      <th>ukuran</th>\n",
       "      <th>harga</th>\n",
       "      <th>labelkelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hijau</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>label1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merah</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>label2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biru</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>label1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warna  ukuran  harga labelkelas\n",
       "0  hijau       1   10.1     label1\n",
       "1  merah       2   13.5     label2\n",
       "2   biru       3   15.3     label1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukuran_mapping = {\n",
    "    'XL': 3,\n",
    "    'L': 2,\n",
    "    'M' : 1\n",
    "}\n",
    "\n",
    "df['ukuran'] = df['ukuran'].map(ukuran_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding label kelas\n",
    "Banyak library machine learning yang membutuhkan lebel kelas yang di encode dengan nilai integer. Untuk melakukan encoding label kelas kita bisa melakukan pendekatan dengan cara yang sama saat melakukan mapping ordinal feature. Hal yang perlu kita ingat adalah bahwa label data bukan bersifat ordinal. Sehingga tidak akan menjadi masalah nomor yang akan ditetapkan untuk label, oleh karena itu kita mulai melakukan enumerasi label dari angka 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label1': 0, 'label2': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warna</th>\n",
       "      <th>ukuran</th>\n",
       "      <th>harga</th>\n",
       "      <th>labelkelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hijau</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merah</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biru</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warna  ukuran  harga  labelkelas\n",
       "0  hijau       1   10.1           0\n",
       "1  merah       2   13.5           1\n",
       "2   biru       3   15.3           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_mapping = {\n",
    "    label: idx for idx, label in enumerate(np.unique(df['labelkelas']))\n",
    "}\n",
    "print(label_mapping)\n",
    "\n",
    "df['labelkelas'] = df['labelkelas'].map(label_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cara alternatif untuk melakukan encoding adalah dengan menggunakan ```LabelEncoder``` yang disediakan oleh library scikit-learn. Beriut adalah implementasi dari ```LabelEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "kelas_le = LabelEncoder()\n",
    "y = kelas_le.fit_transform(df['labelkelas'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### melakukan one-hot encoding pada nominal feature\n",
    "Pembahasan-pembahasan sebelummnya kita sudah memahami bagaimana melakukan konversi data ordinal ke integer dengan menggunakan pendekatan dictionary-mapping. Dengan menggunakan ```LabelEncoder``` yang disediakan oleh library scikit-learn kita bisa melakukan encoding data string menjadi integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels [1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic Acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80      3.06                  0.28             2.29   \n",
       "1           2.65      2.76                  0.26             1.28   \n",
       "2           2.80      3.24                  0.30             2.81   \n",
       "3           3.85      3.49                  0.24             2.18   \n",
       "4           2.80      2.69                  0.39             1.82   \n",
       "\n",
       "   Color Intensity   Hue  OD280/OD315 diluted wines  Proline  \n",
       "0             5.64  1.04                       3.92     1065  \n",
       "1             4.38  1.05                       3.40     1050  \n",
       "2             5.68  1.03                       3.17     1185  \n",
       "3             7.80  0.86                       3.45     1480  \n",
       "4             4.32  1.04                       2.93      735  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol',\n",
    "                  'Malic Acid', 'Ash',\n",
    "                  'Alcalinity of ash', 'Magnesium',\n",
    "                  'Total phenols', 'Flavoids',\n",
    "                  'Nonflavanoid phenols',\n",
    "                  'Proanthocyanins',\n",
    "                  'Color Intensity', 'Hue',\n",
    "                  'OD280/OD315 diluted wines',\n",
    "                  'Proline']\n",
    "print('Class labels', np.unique(df_wine['Class label']))\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blacksmith/.virtualenvs/Machine_Learning/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X,y = df_wine.iloc[:,1:].values, df_wine.iloc[:,0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "Ada dua pendekatan feature scaling yang paling banyak digunakan yaitu ***normalisasi*** dan ***standarisasi***. Pada normalisasi  adalah untuk melakukan pengsekalaan ulang agar feature yang diadapt berada diantara 0 hingga 1, dimana normalisasi merupakan spesial case dari min-max scaling. Untuk melakukan normalisasi data kita perlu mengaplikasikan min-max scaling untuk tiap ffeature, dimana nilai normalisasi $x_{norm}^{i}$ dari data sample $x^{j}$ dapat dihitung dengan menggunakan persamaan\n",
    "\n",
    "$$x_{norm}^{(i)} = \\frac{x^{(i)} - x_{min}}{x_{max}-x_{min}}$$\n",
    "\n",
    "dimana $x^{(i)}$ adalah data sample, $x_{min}$ adalah nilai feature terkecil dan $x_{max}$ adalah nilai feature terbesar. Berikut ini adalah implementasi normalisasi pada scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "x_train_norm = mms.fit_transform(X_train)\n",
    "x_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarisasi adalah salah satu metode yang praktikal digunakan pada algoritma machine learning dikarenakan banyak linear model sperti regresi logistik, SVM, dan sebagainya menginisialisasikan nilai random weight mendekati nilai 0. Dengan menggunakan standarisasi kita memusatkan nilai rata-rata feature menjadi 0 dengan standar deviasi 1, sehingga nilai feature akan terdistribusi secara normal, sehingga memudahkan untuk melakukan learing weight. Untuk melakukan standarisasi bisa dilakukan dengan menggunakan persamaan\n",
    "\n",
    "$$x_{std}^{(i)} = \\frac{x^{(i)}-\\mu_x}{\\sigma_x}$$\n",
    "\n",
    "dimana $\\mu$ adalah nilai rata-rata feature kolom, dan $\\sigma$ adalah nilai untuk standar deviasi. \n",
    "\n",
    "Berikut ini adalah tabel yang membedakan antara normalisasi dengan standari sasi dimana nilai input yang digunakan adalah bilangan integer dari 0 hingga 4\n",
    "\n",
    "| Input | standarisasi | Normalisasi |\n",
    "| ------|:------------:| -----------:|\n",
    "| 0.0   | -1.336306    | 0.0         |\n",
    "| 1.0   | -0.801784    | 0.2         |\n",
    "| 2.0   | -0.267261    | 0.4         |\n",
    "| 3.0   | 0.267261     | 0.6         |\n",
    "| 4.0   | 0.801784     | 0.8         |\n",
    "| 5.0   | 1.336306     | 1.0         |\n",
    "\n",
    "Berikut ini adalah implementasi standarisasi dengan menggunakan library scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memilih feature yang paling relevan\n",
    "ketika model machine learning yang kita gunakan performanya lebih bagus pada data training dibanding pada data testing hal ini menunjukan bahwa model yang kita gunakan mengalamai ***overfitting***, alasan terjadinya overfitting adalah kerana model yang digunakan terlalu kompleks mengklasifikasikan data training, berikut ini adalah beberapa cara untuk mengatasi masalah overfitting\n",
    "* kumpulkan data training lagi\n",
    "* pilih model dengan parameter lebih sedikit\n",
    "* gunakan regularisasi\n",
    "* kurangi dimensi data\n",
    "pada bagian ini dibahas mengani dua cara yaitu mengatasi overfitting dengan regularisasi dan mengurangi dimensi data\n",
    "\n",
    "### L1 Regularisasi\n",
    "Sebenarnya ada dua pendekatan regulasi yang bisa digunakan untuk mengatasi masalah overfitting yaitu ***L2 regularisasi*** dan ***L1 regularisasi***.\n",
    "keduanya memiliki fungsiyang sama yaitu mereduksi kompleksitas suatu model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9838709677419355\n",
      "Test accuracy: 0.9814814814814815\n",
      "intercept: [-0.38380163 -0.15806079 -0.70044752]\n",
      "One-vs-Rest \n",
      " [[ 0.28005163  0.          0.         -0.02811601  0.          0.\n",
      "   0.70994441  0.          0.          0.          0.          0.\n",
      "   1.23657375]\n",
      " [-0.64411304 -0.06874675 -0.05721604  0.          0.          0.\n",
      "   0.          0.          0.         -0.92647981  0.06044378  0.\n",
      "  -0.37112663]\n",
      " [ 0.          0.06164312  0.          0.          0.          0.\n",
      "  -0.63589628  0.          0.          0.49811013 -0.35789701 -0.57144122\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:',lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:',lr.score(X_test_std, y_test))\n",
    "\n",
    "#print intercept\n",
    "print('intercept:',lr.intercept_)\n",
    "\n",
    "#print OvR(One-vs-Rest)\n",
    "print(\"One-vs-Rest \\n\",lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8a24942b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue', 'green', 'red', 'cyan',\n",
    "         'magenta', 'yellow', 'black',\n",
    "         'pink', 'lightgreen', 'lightblue',\n",
    "         'gray', 'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "\n",
    "for c in np.arange(-4, 6, dtype=float):\n",
    "    lr = LogisticRegression(penalty='l1', \n",
    "                            C=10**c, \n",
    "                            random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column+1], \n",
    "             color=color)\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('koefisien bobot')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "ax.legend(loc='upper center',\n",
    "         bbox_to_anchor=(1.3, 1.03),\n",
    "         ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sekuensial feature selection\n",
    "Sekeunsial feature selection adalah algoritma yang berasal dari keluarga greddy yang dignakan untuk mereduksi dimensi awal *d-dimensi* menjadi *k-dimensi*, dimana *k-dimensi* merupakan subspace shingga nilai *k<d*. Algoritma sekeunsial feature selection yang cukup klasik adalah ***Sequntial Backward Selection (SBS)*** tujuan algoritma ini adalah untuk mereduksi dimensi awal ke fitur subspace dengan peluruhan performa yang minimum, shingga SBS mampu meningkatkan prediksi suatu model.\n",
    "\n",
    "Ide dibalik algoritma SBS sangat simple, SBS secara sekuensial mengilangkan feature dari full feature hingga fature mencapai jumlah yang di inginkan. Untuk menentukan feature mana yang akan dihilangkan perlu ditentukan fungsi kriteria nilai $J$ yang ingin kita minimalkan. Berikut ini adalah 4 langkah algoritma SBS\n",
    "1. Inisiali Algoritma SBS dengan nilai $k=d$, dimana $d$ adalah dimensi dari ruang feature $X_d$\n",
    "2. Tentukan fitur $X^-$ yang memaksimalkan $X^- = argmaxJ(X_k - x)$ dimana x\n",
    "3. Hilangkan feature $x^-$ dari feature set $X_{k-1} := X_k - x^-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, \n",
    "                 scoring=accuracy_score, test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    \n",
    "    def fit(X,y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size,\n",
    "                                                          random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices = tuple(range(dim))\n",
    "        self.subsets = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train,\n",
    "                                X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            \n",
    "            for p in combinations(self.indices_, r = dim-1):\n",
    "                score = self._calc_score(X_train, y_train,\n",
    "                                        X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            \n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            \n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score = self.scores_[-1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "    \n",
    "    \n",
    "    def _calc_score(self, X_train, y_train,\n",
    "                   X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoreing(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "sbs = SBS(knn, k_feature=1)\n",
    "sbs.fit(X_train_std, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
